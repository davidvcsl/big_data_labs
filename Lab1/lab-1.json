{"paragraphs":[{"text":"%dep z.load(\"org.scalaj:scalaj-http_2.10:2.1.0\")","user":"anonymous","dateUpdated":"2017-10-06T01:04:33-0300","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@158a4b85\n"}]},"apps":[],"jobName":"paragraph_1507262606327_1792952069","id":"20170930-221600_1859919435","dateCreated":"2017-10-06T01:03:26-0300","dateStarted":"2017-10-06T01:04:33-0300","dateFinished":"2017-10-06T01:04:39-0300","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2461"},{"title":"Imports","text":"import org.apache.spark.rdd.RDD\nimport org.joda.time.LocalDate\nimport org.apache.spark.SparkContext._\nimport java.io.StringReader\nimport au.com.bytecode.opencsv.CSVReader\nimport scalaj.http._\nimport scala.util.parsing.json._\nimport collection.mutable","dateUpdated":"2017-10-06T01:04:50-0300","config":{"enabled":true,"title":true,"tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","results":{},"editorHide":false,"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\nimport org.joda.time.LocalDate\nimport org.apache.spark.SparkContext._\nimport java.io.StringReader\nimport au.com.bytecode.opencsv.CSVReader\nimport scalaj.http._\nimport scala.util.parsing.json._\nimport collection.mutable\n"}]},"apps":[],"jobName":"paragraph_1507262606327_1792952069","id":"20160720-193407_10576745","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2462","user":"anonymous","dateFinished":"2017-10-06T01:04:59-0300","dateStarted":"2017-10-06T01:04:51-0300"},{"title":"Primer Parte: Funciones","text":"/** Carga un archivo en memoria y retorna un RDD. \n  *  \n  *  @param \tfile\t\t\t\tPath al archivo \n  *  @return\tRDD[Array[String]]\tCada Array[String] tiene 6 elementos:\n  *  \t\t\t\t\t\t\t\tdate, doi, ip_code, country, city, coords\n */\ndef loadFile(file : String) : RDD[Array[String]] = {\n    val fileRDD = sc.textFile(file)\n    val arrayOfLines = fileRDD.map(line => line.split(\"\\t\", 6)).filter(_.size == 6) //Armamos el arreglo de 6 elementos\n    arrayOfLines\n}   \n\n/** Carga una lista de archivos en memoria y retorna un unico \n  * RDD[Array[String]] con el contenido de todos los archivos. \n  *  \n  *  @param \tfiles\t\t\t\tLista de paths\n  *  @return\tRDD[Array[String]]\tCada Array[String] tiene 6 elementos:\n  *  \t\t\t\t\t\t\t\tdate, doi, ip_code, country, city, coords\n */\ndef loadDataset(files:List[String]) : RDD[Array[String]] ={\n    var RDDS = loadFile(files(0))\n    var i = 1\n    while (i<files.length){\n        val newRDD = loadFile(files(i))\n        i += 1\n        RDDS = RDDS.union(newRDD)\n    }\n    RDDS\n}\n\n/** Transforma un RDD[Array(String)] en un RDD[(DateTime,Int)].\n  *  \n  *  @param \traw\t\t\t\t\tDataset \"crudo\" de sci-hub.\n  *  @return\tRDD[(LocalDate,Int)]\t\n */\ndef toDateTuple(raw: RDD[Array[String]]) : RDD[(LocalDate, Int)] = {\n    val newRDD = raw.map(arr => (LocalDate.parse(arr(0).split(\" \")(0)),1)) //Parseamos el primer elemento del arreglo y lo spliteamos por espacio para tomar la fecha\n    newRDD\n}\n\ndef aggregateByDay(data :  RDD[(LocalDate, Int)]) = {\n    val tuples = data.reduceByKey(_ + _) //(fecha, descargas)\n    tuples\n}\n\ndef aggregateByMonth(data :  RDD[(LocalDate, Int)]) = {\n    val newkeys = data.map{case (x,y) => (x.getYear().toString ++ \"-\" ++ x.getMonthOfYear().toString,y)} //Para que nos quede año-mes\n    val tuples = newkeys.reduceByKey(_ + _) //(año-mes, descargas)\n    tuples\n}\n\ndef aggregateByWeekDay(data :  RDD[(LocalDate, Int)])  = {\n    val newkeys = data.map{case (x,y) => (x.getDayOfWeek(),y)} //Calculamos el dia de la semana\n    val tuples = newkeys.reduceByKey(_ + _) //(dia de la semana, descargas)\n    tuples\n}\n","dateUpdated":"2017-10-06T01:24:30-0300","config":{"enabled":true,"title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"loadFile: (file: String)org.apache.spark.rdd.RDD[Array[String]]\nloadDataset: (files: List[String])org.apache.spark.rdd.RDD[Array[String]]\ntoDateTuple: (raw: org.apache.spark.rdd.RDD[Array[String]])org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)]\naggregateByDay: (data: org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)])org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)]\naggregateByMonth: (data: org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)])org.apache.spark.rdd.RDD[(String, Int)]\naggregateByWeekDay: (data: org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)])org.apache.spark.rdd.RDD[(Int, Int)]\n"}]},"apps":[],"jobName":"paragraph_1507262606328_1791028325","id":"20160828-194457_160895440","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2463","user":"anonymous","dateFinished":"2017-10-06T01:24:31-0300","dateStarted":"2017-10-06T01:24:31-0300"},{"title":"Primera Parte: Ejecucion","text":"","dateUpdated":"2017-10-06T01:30:21-0300","config":{"enabled":true,"title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","results":{"1":{"graph":{"mode":"stackedAreaChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"load: org.apache.spark.rdd.RDD[Array[String]] = UnionRDD[396] at union at <console>:59\n"}]},"apps":[],"jobName":"paragraph_1507262606328_1791028325","id":"20160830-101603_128796092","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2464","user":"anonymous","dateFinished":"2017-10-06T01:27:04-0300","dateStarted":"2017-10-06T01:27:03-0300"},{"title":"Descargas x Dia","text":"val load = loadDataset(List(\"scihub_data/dec2015.tab\",\"scihub_data/feb2016.tab\",\"scihub_data/jan2016.tab\",\"scihub_data/nov2015.tab\",\"scihub_data/oct2015.tab\",\"scihub_data/sep2015.tab\"))\nimplicit def dateTimeOrdering: Ordering[LocalDate] = Ordering.fromLessThan(_ isBefore _)\nval dates = toDateTuple(load) //(fecha,1)\n\nvar mList : mutable.ListBuffer[LocalDate] = mutable.ListBuffer() //Cargar todas las fechas\nvar startDate = LocalDate.parse(\"2015-9-01\")\nvar endDate = LocalDate.parse(\"2016-3-01\")\nwhile (!startDate.isAfter(endDate)) {\n mList += startDate;\n startDate = startDate.plusDays(1);\n}\nval datesEmptArr = mList.toArray\nval allDatesCeros = sc.parallelize(datesEmptArr).map(x => (x,0)) //Inicializamos todas las fechas con 0 \nval allDatesJoin = allDatesCeros.leftOuterJoin(dates).map{case (x,y) => (x,y._2.getOrElse(0))} //Join de las fechas: (fecha, (0,None)) o (fecha,(0,Some(1))\n\nval agg = aggregateByDay(allDatesJoin).collect().sortBy(_._1) //(fecha,descargas)\nprintln(\"\\n%table Day\\tDownloads\\n\")\nagg.foreach(l => println(\"\\\"\" + l._1 + \"\\\"\" + \"\\t\" + l._2))","dateUpdated":"2017-10-06T01:30:25-0300","config":{"enabled":true,"title":true,"results":[{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"keys":[{"name":"Date","index":0,"aggr":"sum"}],"values":[{"name":"Downloads","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"Date","index":0,"aggr":"sum"},"yAxis":{"name":"Downloads","index":1,"aggr":"sum"}}},"helium":{}},{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false},"helium":{}}],"editorMode":"ace/mode/scala","editorHide":false,"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"load: org.apache.spark.rdd.RDD[Array[String]] = UnionRDD[70] at union at <console>:57\ndateTimeOrdering: Ordering[org.joda.time.LocalDate]\ndates: org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)] = MapPartitionsRDD[71] at map at <console>:47\nmList: scala.collection.mutable.ListBuffer[org.joda.time.LocalDate] = ListBuffer()\nstartDate: org.joda.time.LocalDate = 2015-09-01\nendDate: org.joda.time.LocalDate = 2016-03-01\ndatesEmptArr: Array[org.joda.time.LocalDate] = Array(2015-09-01, 2015-09-02, 2015-09-03, 2015-09-04, 2015-09-05, 2015-09-06, 2015-09-07, 2015-09-08, 2015-09-09, 2015-09-10, 2015-09-11, 2015-09-12, 2015-09-13, 2015-09-14, 2015-09-15, 2015-09-16, 2015-09-17, 2015-09-18, 2015-09-19, 2015-09-20, 2015-09-21, 2015-09-22, 2015-09-23, 2015-09-24, 2015-09-25, 2015-09-26, 2015-09-27, 2015-09-28, 2015-09-29, 2015-09-30, 2015-10-01, 2015-10-02, 2015-10-03, 2015-10-04, 2015-10-05, 2015-10-06, 2015-10-07, 2015-10-08, 2015-10-09, 2015-10-10, 2015-10-11, 2015-10-12, 2015-10-13, 2015-10-14, 2015-10-15, 2015-10-16, 2015-10-17, 2015-10-18, 2015-10-19, 2015-10-20, 2015-10-21, 2015-10-22, 2015-10-23, 2015-10-24, 2015-10-25, 2015-10-26, 2015-10-27, 2015-10-28, 2015-10-29, 2015-10-30, 2015-10-31, 2015-11-01, ...allDatesCeros: org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)] = MapPartitionsRDD[73] at map at <console>:47\nallDatesJoin: org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)] = MapPartitionsRDD[77] at map at <console>:59\nagg: Array[(org.joda.time.LocalDate, Int)] = Array((2015-09-01,259212), (2015-09-02,216188), (2015-09-03,164475), (2015-09-04,141425), (2015-09-05,91168), (2015-09-06,121198), (2015-09-07,126391), (2015-09-08,161909), (2015-09-09,106014), (2015-09-10,168581), (2015-09-11,178039), (2015-09-12,136263), (2015-09-13,128320), (2015-09-14,181225), (2015-09-15,179402), (2015-09-16,191777), (2015-09-17,182311), (2015-09-18,136835), (2015-09-19,136283), (2015-09-20,135501), (2015-09-21,217846), (2015-09-22,195031), (2015-09-23,185905), (2015-09-24,161953), (2015-09-25,159892), (2015-09-26,119559), (2015-09-27,125160), (2015-09-28,205225), (2015-09-29,201481), (2015-09-30,189749), (2015-10-01,163759), (2015-10-02,144241), (2015-10-03,125717), (2015-10-04,130392), (2015-10-05,209610), (2015-10-06,...\n"},{"type":"TABLE","data":"Day\tDownloads\n\"2015-09-01\"\t259212\n\"2015-09-02\"\t216188\n\"2015-09-03\"\t164475\n\"2015-09-04\"\t141425\n\"2015-09-05\"\t91168\n\"2015-09-06\"\t121198\n\"2015-09-07\"\t126391\n\"2015-09-08\"\t161909\n\"2015-09-09\"\t106014\n\"2015-09-10\"\t168581\n\"2015-09-11\"\t178039\n\"2015-09-12\"\t136263\n\"2015-09-13\"\t128320\n\"2015-09-14\"\t181225\n\"2015-09-15\"\t179402\n\"2015-09-16\"\t191777\n\"2015-09-17\"\t182311\n\"2015-09-18\"\t136835\n\"2015-09-19\"\t136283\n\"2015-09-20\"\t135501\n\"2015-09-21\"\t217846\n\"2015-09-22\"\t195031\n\"2015-09-23\"\t185905\n\"2015-09-24\"\t161953\n\"2015-09-25\"\t159892\n\"2015-09-26\"\t119559\n\"2015-09-27\"\t125160\n\"2015-09-28\"\t205225\n\"2015-09-29\"\t201481\n\"2015-09-30\"\t189749\n\"2015-10-01\"\t163759\n\"2015-10-02\"\t144241\n\"2015-10-03\"\t125717\n\"2015-10-04\"\t130392\n\"2015-10-05\"\t209610\n\"2015-10-06\"\t202665\n\"2015-10-07\"\t196240\n\"2015-10-08\"\t219405\n\"2015-10-09\"\t211024\n\"2015-10-10\"\t175451\n\"2015-10-11\"\t164789\n\"2015-10-12\"\t241172\n\"2015-10-13\"\t238358\n\"2015-10-14\"\t236997\n\"2015-10-15\"\t228642\n\"2015-10-16\"\t217571\n\"2015-10-17\"\t151682\n\"2015-10-18\"\t159507\n\"2015-10-19\"\t234930\n\"2015-10-20\"\t211899\n\"2015-10-21\"\t221229\n\"2015-10-22\"\t206038\n\"2015-10-23\"\t194017\n\"2015-10-24\"\t144169\n\"2015-10-25\"\t162015\n\"2015-10-26\"\t239419\n\"2015-10-27\"\t235817\n\"2015-10-28\"\t227398\n\"2015-10-29\"\t216588\n\"2015-10-30\"\t203869\n\"2015-10-31\"\t157537\n\"2015-11-01\"\t158860\n\"2015-11-02\"\t242674\n\"2015-11-03\"\t250108\n\"2015-11-04\"\t137325\n\"2015-11-05\"\t0\n\"2015-11-06\"\t0\n\"2015-11-07\"\t0\n\"2015-11-08\"\t0\n\"2015-11-09\"\t0\n\"2015-11-10\"\t0\n\"2015-11-11\"\t0\n\"2015-11-12\"\t0\n\"2015-11-13\"\t0\n\"2015-11-14\"\t0\n\"2015-11-15\"\t0\n\"2015-11-16\"\t0\n\"2015-11-17\"\t0\n\"2015-11-18\"\t0\n\"2015-11-19\"\t0\n\"2015-11-20\"\t0\n\"2015-11-21\"\t0\n\"2015-11-22\"\t39967\n\"2015-11-23\"\t132895\n\"2015-11-24\"\t139344\n\"2015-11-25\"\t135707\n\"2015-11-26\"\t125278\n\"2015-11-27\"\t126436\n\"2015-11-28\"\t98349\n\"2015-11-29\"\t109454\n\"2015-11-30\"\t152988\n\"2015-12-01\"\t159110\n\"2015-12-02\"\t159873\n\"2015-12-03\"\t153125\n\"2015-12-04\"\t141592\n\"2015-12-05\"\t115699\n\"2015-12-06\"\t118645\n\"2015-12-07\"\t160000\n\"2015-12-08\"\t162162\n\"2015-12-09\"\t166353\n\"2015-12-10\"\t163833\n\"2015-12-11\"\t160983\n\"2015-12-12\"\t123507\n\"2015-12-13\"\t110384\n\"2015-12-14\"\t99728\n\"2015-12-15\"\t179622\n\"2015-12-16\"\t197410\n\"2015-12-17\"\t159985\n\"2015-12-18\"\t143163\n\"2015-12-19\"\t113947\n\"2015-12-20\"\t117865\n\"2015-12-21\"\t159852\n\"2015-12-22\"\t169552\n\"2015-12-23\"\t57566\n\"2015-12-24\"\t81695\n\"2015-12-25\"\t87229\n\"2015-12-26\"\t99907\n\"2015-12-27\"\t0\n\"2015-12-28\"\t9534\n\"2015-12-29\"\t60021\n\"2015-12-30\"\t140105\n\"2015-12-31\"\t107062\n\"2016-01-01\"\t87277\n\"2016-01-02\"\t112029\n\"2016-01-03\"\t111728\n\"2016-01-04\"\t163768\n\"2016-01-05\"\t172209\n\"2016-01-06\"\t119157\n\"2016-01-07\"\t132052\n\"2016-01-08\"\t85761\n\"2016-01-09\"\t121763\n\"2016-01-10\"\t126172\n\"2016-01-11\"\t177125\n\"2016-01-12\"\t182815\n\"2016-01-13\"\t173148\n\"2016-01-14\"\t170317\n\"2016-01-15\"\t157783\n\"2016-01-16\"\t127633\n\"2016-01-17\"\t134223\n\"2016-01-18\"\t193387\n\"2016-01-19\"\t199521\n\"2016-01-20\"\t197684\n\"2016-01-21\"\t198652\n\"2016-01-22\"\t219520\n\"2016-01-23\"\t158933\n\"2016-01-24\"\t147636\n\"2016-01-25\"\t209929\n\"2016-01-26\"\t199233\n\"2016-01-27\"\t198213\n\"2016-01-28\"\t189977\n\"2016-01-29\"\t174113\n\"2016-01-30\"\t137935\n\"2016-01-31\"\t121819\n\"2016-02-01\"\t200054\n\"2016-02-02\"\t198192\n\"2016-02-03\"\t200592\n\"2016-02-04\"\t190509\n\"2016-02-05\"\t178126\n\"2016-02-06\"\t143356\n\"2016-02-07\"\t123561\n\"2016-02-08\"\t184710\n\"2016-02-09\"\t187652\n\"2016-02-10\"\t192981\n\"2016-02-11\"\t193218\n\"2016-02-12\"\t224429\n\"2016-02-13\"\t207334\n\"2016-02-14\"\t163895\n\"2016-02-15\"\t208310\n\"2016-02-16\"\t255052\n\"2016-02-17\"\t250275\n\"2016-02-18\"\t242040\n\"2016-02-19\"\t228539\n\"2016-02-20\"\t194618\n\"2016-02-21\"\t201729\n\"2016-02-22\"\t263404\n\"2016-02-23\"\t276574\n\"2016-02-24\"\t287524\n\"2016-02-25\"\t285294\n\"2016-02-26\"\t258522\n\"2016-02-27\"\t191950\n\"2016-02-28\"\t197995\n\"2016-02-29\"\t282656\n\"2016-03-01\"\t2\n"}]},"apps":[],"jobName":"paragraph_1507262606329_1790643576","id":"20160829-212142_1138855898","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2465","user":"anonymous","dateFinished":"2017-10-06T01:07:35-0300","dateStarted":"2017-10-06T01:06:35-0300"},{"title":"Descargas x Mes","text":"val load = loadDataset(List(\"scihub_data/dec2015.tab\",\"scihub_data/feb2016.tab\",\"scihub_data/jan2016.tab\",\"scihub_data/nov2015.tab\",\"scihub_data/oct2015.tab\",\"scihub_data/sep2015.tab\"))\nval dates = toDateTuple(load)\nval agg = aggregateByMonth(dates).collect().sortBy{case (x,y) => LocalDate.parse(x)} //Obtenemos (mes, descargas) y lo ordenamos de menor a mayor\nprintln(\"%table Month\\tDownloads\\n\")\nagg.foreach(l => println(\"\\\"\" + l._1 + \"\\\"\" + \"\\t\" + l._2))","dateUpdated":"2017-10-06T01:30:28-0300","config":{"enabled":true,"title":true,"results":[{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"keys":[{"name":"Month","index":0,"aggr":"sum"}],"values":[{"name":"Downloads","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"Month","index":0,"aggr":"sum"},"yAxis":{"name":"Downloads","index":1,"aggr":"sum"}}}},{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}],"editorMode":"ace/mode/scala","editorHide":false,"editorSetting":{"language":"scala"},"colWidth":6},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"load: org.apache.spark.rdd.RDD[Array[String]] = UnionRDD[300] at union at <console>:59\ndates: org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)] = MapPartitionsRDD[301] at map at <console>:49\nagg: Array[(String, Int)] = Array((2015-9,4904318), (2015-10,6072147), (2015-11,1849385), (2015-12,3879509), (2016-1,4901512), (2016-2,6213091), (2016-3,2))\n"},{"type":"TABLE","data":"Month\tDownloads\n\"2015-9\"\t4904318\n\"2015-10\"\t6072147\n\"2015-11\"\t1849385\n\"2015-12\"\t3879509\n\"2016-1\"\t4901512\n\"2016-2\"\t6213091\n\"2016-3\"\t2\n"}]},"apps":[],"jobName":"paragraph_1507262606329_1790643576","id":"20160829-212442_607988519","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2466","user":"anonymous","dateFinished":"2017-10-06T01:24:16-0300","dateStarted":"2017-10-06T01:23:23-0300"},{"title":"Descargas x Dia de la Semana","text":"val load = loadDataset(List(\"scihub_data/dec2015.tab\",\"scihub_data/feb2016.tab\",\"scihub_data/jan2016.tab\",\"scihub_data/nov2015.tab\",\"scihub_data/oct2015.tab\",\"scihub_data/sep2015.tab\"))\nval dates = toDateTuple(load)\nval agg = aggregateByWeekDay(dates).collect() //Obtenemos (dia de la semana, descargas)\nprintln(\"%table WeekDay\\tDownloads\\n\")\nagg.foreach(l => println(\"\\\"\" + l._1 + \"\\\"\" + \"\\t\" + l._2))","dateUpdated":"2017-10-06T01:30:33-0300","config":{"enabled":true,"title":true,"results":[{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"keys":[{"name":"Day","index":0,"aggr":"sum"}],"values":[{"name":"Downloads","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"Day","index":0,"aggr":"sum"},"yAxis":{"name":"Downloads","index":1,"aggr":"sum"}}}},{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}],"editorMode":"ace/mode/scala","editorHide":false,"editorSetting":{"language":"scala"},"colWidth":6},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"load: org.apache.spark.rdd.RDD[Array[String]] = UnionRDD[428] at union at <console>:59\ndates: org.apache.spark.rdd.RDD[(org.joda.time.LocalDate, Int)] = MapPartitionsRDD[429] at map at <console>:48\nagg: Array[(Int, Int)] = Array((1,4496832), (2,4676943), (3,4385410), (4,4104789), (5,3860386), (6,3184789), (7,3110815))\n"},{"type":"TABLE","data":"WeekDay\tDownloads\n\"1\"\t4496832\n\"2\"\t4676943\n\"3\"\t4385410\n\"4\"\t4104789\n\"5\"\t3860386\n\"6\"\t3184789\n\"7\"\t3110815\n"}]},"apps":[],"jobName":"paragraph_1507262606330_1791797823","id":"20160829-212549_353556239","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2467","user":"anonymous","dateFinished":"2017-10-06T01:31:28-0300","dateStarted":"2017-10-06T01:30:33-0300"},{"title":"Segunda Parte: Funciones","text":"/** Carga un archivo contiene el mapeo prefix -> publisher.\n*  \n*  @param \tfile\t\t\t\t\tPath al archivo.\n*  @return\tRDD[(String,String)] \t\n*/\ndef loadPrefixMapping(file : String) : RDD[(String, String)] = {\n    val rdd = sc.textFile(file)  //Cargamos el csv\n    val result = rdd.map{ line =>\n        val reader = new CSVReader(new StringReader(line));  //Parseamos el csv\n        reader.readNext();\n    }\n    val tuples = result.collect().drop(3).map(x => (x(2),x(1))) //(Array(\"\", Name, Prefix, Date Joined), Array(\"Last Deposit,Date of \"), null, Array(0, Povolzhskiy, 10.18469, \"\", Dec 16, 2015, unknown)\n    val tuplesRDD = sc.parallelize(tuples) //(prefix, edit) \n    tuplesRDD\n}\n\n/** Retorna la metadata asociada a un DOI\n*  \n*  @param \tdoi\t\t\t\t\tDOI\n*  @return\t... \t\n*/\ndef getMetadata(doi:String) = {\n    val request = Http(\"https://api.crossref.org/works/\" + doi).asString.toString.drop(13).split(\",200,Map\")(0) //Hacemos el request,asString nos devuelve un httpresponse[string] = HttpResponse({\"status\":\"ok\"..., lo pasamos a string y devolvemos la parte del json\n    val result = JSON.parseFull(request) //Parseamos json, devuelve Option[Any]\n    val mapp = result.getOrElse(Map(\"N/A\"->\"N/A\")).asInstanceOf[Map[String, Any]] //Entramos al \"primer nivel\". Usamos getOrElse por si lo que buscamos devuelve None y le queremos hacer get\n    val msg = mapp.get(\"message\").getOrElse(Map(\"N/A\"->\"N/A\")).asInstanceOf[Map[String, Any]] //Entramos al \"segundo nivel\", donde esta toda la informacion que buscamos\n    val gettitulo = msg.get(\"title\").getOrElse(List(\"N/A\")).asInstanceOf[List[String]] //Buscamos el titulo,subject y libro, los cuales vienen en una lista con el string dentro (hay que analizar si la lista es no vacia)\n    val titulo = if (!gettitulo.isEmpty) gettitulo(0) else \"N/A\"\n    val getsubject = msg.get(\"subject\").getOrElse(List(\"N/A\")).asInstanceOf[List[String]]\n    val subject = if (!getsubject.isEmpty) getsubject(0) else \"N/A\"\n    val getlibro = msg.get(\"container-title\").getOrElse(List(\"N/A\")).asInstanceOf[List[String]]\n    val libro = if (!getlibro.isEmpty) getlibro(0) else \"N/A\"\n    val publisher = msg.get(\"publisher\").getOrElse(\"N/A\").asInstanceOf[String] //el publisher y el tipo vienen con el string \"suelto\"\n    val tipo = msg.get(\"type\").getOrElse(\"N/A\").asInstanceOf[String]\n    val pub = msg.get(\"published-print\").getOrElse(Map(\"N/A\"->\"N/A\")).asInstanceOf[Map[String, Any]] //Aca entramos en otro nivel para obtener la fecha de pub\n    val getpub_date = pub.get(\"date-parts\").getOrElse(List(List(\"0.0\".toDouble))).asInstanceOf[List[List[Double]]] //la fecha viene dada como [[fecha]]\n    val pub_date = if (!getpub_date(0).isEmpty) getpub_date(0)(0) else \"N/A\" // Verificamos que la lista no sea vacia\n    val public_date = if (pub_date == 0.0) \"N/A\" else pub_date //En caso que la fecha no este cambiamos el 0 N/A\n    val lista = List(titulo, subject, libro, publisher, tipo, public_date)\n    lista\n}\n\ndef aggregateByDoi(inputRDD: RDD[Array[String]]) = {\n    val data = inputRDD.map(arr => (arr(1),1)) // arr(date, doi, ip_code, country, city, coords) y doi = 1234/asd.567\n    val tuples = data.reduceByKey(_ + _) //(doi,cant)\n    tuples\n}\n\ndef aggregateByPrefix(inputRDD: RDD[Array[String]]) = {\n    val data = inputRDD.map(arr => (arr(1).split(\"/\")(0),1)) // arr(date, doi, ip_code, country, city, coords) y doi = prefix/asd.567\n    val tuples = data.reduceByKey(_ + _) //(prefix,cant)\n    tuples\n}\n\ndef aggregateByCountry(inputRDD: RDD[Array[String]]) = {\n    val data = inputRDD.map(arr => (arr(3),1)) //arr(date, doi, ip_code, country, city, coords)\n    val tuples = data.reduceByKey(_ + _)\n    tuples\n}","dateUpdated":"2017-10-06T01:08:33-0300","config":{"enabled":true,"title":true,"tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","results":{},"editorHide":false,"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"loadPrefixMapping: (file: String)org.apache.spark.rdd.RDD[(String, String)]\ngetMetadata: (doi: String)List[Any]\naggregateByDoi: (inputRDD: org.apache.spark.rdd.RDD[Array[String]])org.apache.spark.rdd.RDD[(String, Int)]\naggregateByPrefix: (inputRDD: org.apache.spark.rdd.RDD[Array[String]])org.apache.spark.rdd.RDD[(String, Int)]\naggregateByCountry: (inputRDD: org.apache.spark.rdd.RDD[Array[String]])org.apache.spark.rdd.RDD[(String, Int)]\n"}]},"apps":[],"jobName":"paragraph_1507262606331_1791413074","id":"20160720-200109_863303752","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2468","user":"anonymous","dateFinished":"2017-10-06T01:08:34-0300","dateStarted":"2017-10-06T01:08:33-0300"},{"title":"Segunda Parte: Ejecucion","text":"","dateUpdated":"2017-10-06T01:03:26-0300","config":{"enabled":true,"title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507262606331_1791413074","id":"20160830-191755_1665458610","dateCreated":"2017-10-06T01:03:26-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2469"},{"title":"Top 10 - Editoriales","text":"val load = loadDataset(List(\"scihub_data/dec2015.tab\",\"scihub_data/feb2016.tab\",\"scihub_data/jan2016.tab\",\"scihub_data/nov2015.tab\",\"scihub_data/oct2015.tab\",\"scihub_data/sep2015.tab\"))\nval edTuples = loadPrefixMapping(\"scihub_data/publisher_DOI_prefixes2.csv\").distinct  //(prefix,edit) y sacamos los repetidos (misma edit con mismo prefix)\nval aggr = aggregateByPrefix(load) // (prefix, cant)\nval tups = aggr.join(edTuples).map{case (x,y) => (y._2,y._1)}.reduceByKey(_ + _) // (prefix,(cant,edit)) => (edit,cant) y juntamos por clave para capturar misma editorial pero con distinto prefix\nval plot = tups.sortBy(_._2,false).take(10) //ordeno por cantidad y tomo 10\nprintln(\"%table Publisher\\tDownloads\\n\")\nplot.foreach(l => println(\"\\\"\" + l._1 + \"\\\"\" + \"\\t\" + l._2))\n\n","dateUpdated":"2017-10-06T01:30:41-0300","config":{"enabled":true,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"Publisher","index":0,"aggr":"sum"}],"values":[{"name":"Downloads","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"Publisher","index":0,"aggr":"sum"},"yAxis":{"name":"Downloads","index":1,"aggr":"sum"}}},"helium":{}},{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}],"editorMode":"ace/mode/scala","editorHide":false,"editorSetting":{"language":"scala"},"colWidth":6},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"load: org.apache.spark.rdd.RDD[Array[String]] = UnionRDD[179] at union at <console>:59\nedTuples: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[186] at distinct at <console>:45\naggr: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[188] at reduceByKey at <console>:44\ntups: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[193] at reduceByKey at <console>:57\nplot: Array[(String, Int)] = Array((Elsevier,9296486), (Springer-Verlag,2630787), (Institute of Electrical and Electronics Engineers,2138064), (American Chemical Society,1871934), (Wiley Blackwell (John Wiley & Sons),1367250), (Nature Publishing Group,1121881), (The Royal Society of Chemistry,927239), (Informa UK (Taylor & Francis),906221), (Wiley Blackwell (Blackwell Publishing),880343), (SAGE Publications,377267))\n"},{"type":"TABLE","data":"Publisher\tDownloads\n\"Elsevier\"\t9296486\n\"Springer-Verlag\"\t2630787\n\"Institute of Electrical and Electronics Engineers\"\t2138064\n\"American Chemical Society\"\t1871934\n\"Wiley Blackwell (John Wiley & Sons)\"\t1367250\n\"Nature Publishing Group\"\t1121881\n\"The Royal Society of Chemistry\"\t927239\n\"Informa UK (Taylor & Francis)\"\t906221\n\"Wiley Blackwell (Blackwell Publishing)\"\t880343\n\"SAGE Publications\"\t377267\n"}]},"apps":[],"jobName":"paragraph_1507262606332_1789489329","id":"20160814-113813_1049909467","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2470","user":"anonymous","dateFinished":"2017-10-06T01:19:30-0300","dateStarted":"2017-10-06T01:18:35-0300"},{"title":"Top 10 - Paises","text":"val load = loadDataset(List(\"scihub_data/dec2015.tab\",\"scihub_data/feb2016.tab\",\"scihub_data/jan2016.tab\",\"scihub_data/nov2015.tab\",\"scihub_data/oct2015.tab\",\"scihub_data/sep2015.tab\"))\nval agg = aggregateByCountry(load) //(pais,cant)\nval plot = agg.sortBy(_._2,false).take(10)\nprintln(\"%table Country\\tDownloads\\n\")\nplot.foreach(l => println(\"\\\"\" + l._1 + \"\\\"\" + \"\\t\" + l._2))","dateUpdated":"2017-10-06T01:30:44-0300","config":{"enabled":true,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"Country","index":0,"aggr":"sum"}],"values":[{"name":"Downloads","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"Country","index":0,"aggr":"sum"},"yAxis":{"name":"Downloads","index":1,"aggr":"sum"}}}},{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}],"editorMode":"ace/mode/scala","editorHide":false,"editorSetting":{"language":"scala"},"colWidth":6},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"load: org.apache.spark.rdd.RDD[Array[String]] = UnionRDD[227] at union at <console>:59\nagg: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[229] at reduceByKey at <console>:44\nplot: Array[(String, Int)] = Array((China,4456076), (India,3414582), (Iran,2631035), (Russia,1521434), (United States,1150963), (Brazil,1021540), (Egypt,801106), (Indonesia,780873), (N/A,562692), (France,511145))\n"},{"type":"TABLE","data":"Country\tDownloads\n\"China\"\t4456076\n\"India\"\t3414582\n\"Iran\"\t2631035\n\"Russia\"\t1521434\n\"United States\"\t1150963\n\"Brazil\"\t1021540\n\"Egypt\"\t801106\n\"Indonesia\"\t780873\n\"N/A\"\t562692\n\"France\"\t511145\n"}]},"apps":[],"jobName":"paragraph_1507262606333_1789104580","id":"20160830-185322_186078579","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2471","user":"anonymous","dateFinished":"2017-10-06T01:21:12-0300","dateStarted":"2017-10-06T01:20:16-0300"},{"title":"Top 10 - Articulos","text":"val load = loadDataset(List(\"scihub_data/dec2015.tab\",\"scihub_data/feb2016.tab\",\"scihub_data/jan2016.tab\",\"scihub_data/nov2015.tab\",\"scihub_data/oct2015.tab\",\"scihub_data/sep2015.tab\"))\nval aggreg = aggregateByDoi(load) //(doi,cant)\nval plot = aggreg.sortBy(_._2,false).take(10)\nval metadata = plot.map{case (x,y) => { val meta = getMetadata(x);\n                                (x,meta(0),meta(5),meta(4),meta(3),meta(2),meta(1),y)}}\nprintln(\"\\n%table DOI\\tTitle\\tYear\\tType\\tPublisher\\tBook\\tSubject\\tDownloads\\n\")\nmetadata.foreach(l => println(\"\\\"\" + l._1 + \"\\\"\" + \"\\t\" + l._2 + \"\\\"\" + \"\\t\" + l._3 + \"\\\"\" + \"\\t\" +l._4 + \"\\\"\" + \"\\t\" +l._5 + \"\\\"\" + \"\\t\" +l._6 + \"\\\"\" + \"\\t\" +l._7 + \"\\\"\" + \"\\t\" + l._8))\n","dateUpdated":"2017-10-06T01:30:49-0300","config":{"enabled":true,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"DOI","index":0,"aggr":"sum"}],"values":[{"name":"Title","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"DOI","index":0,"aggr":"sum"},"yAxis":{"name":"Title","index":1,"aggr":"sum"}}},"helium":{}},{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}],"editorMode":"ace/mode/scala","editorHide":false,"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"load: org.apache.spark.rdd.RDD[Array[String]] = UnionRDD[143] at union at <console>:59\naggreg: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[145] at reduceByKey at <console>:44\nplot: Array[(String, Int)] = Array((10.1007/978-1-4419-9716-6_11,7988), (10.1056/NEJMoa1402121,6117), (10.1116/1.4904970,2991), (10.1103/PhysRevB.63.224204,2890), (10.1182/asheducation-2015.1.8,2528), (10.4028/www.scientific.net/AMM.7-8.159,2266), (10.1111/j.1365-277X.2004.00520.x,2241), (10.1002/pmic.200600525,2168), (10.1161/CIRCRESAHA.117.306290,2001), (10.1002/smll.201002009,1806))\nmetadata: Array[(String, Any, Any, Any, Any, Any, Any, Int)] = Array((10.1007/978-1-4419-9716-6_11,Full-scale modal wind turbine tests: comparing shaker excitation with wind excitation,2011.0,book-chapter,Springer New York,Structural Dynamics and Renewable Energy, Volume 1,N/A,7988), (10.1056/NEJMoa1402121,Comprehensive, Integrative Genomic Analysis of Diffuse Lower-Grade Gliomas,2015.0,journal-article,New England Journal of Medicine (NEJM/MMS),New England Journal of Medicine,General Medicine,6117), (10.1116/1.4904970,Photosensitive field emission study of SnS2 nanosheets,2015.0,journal-article,American Vacuum Society,Journal of Vacuum Science & Technology B, Nanotechnology and Microelectronics: Materials, Processing, Measurement, and Phenomena,Instrumentation,2991), (10.1103/PhysRevB.6...\n"},{"type":"TABLE","data":"DOI\tTitle\tYear\tType\tPublisher\tBook\tSubject\tDownloads\n\"10.1007/978-1-4419-9716-6_11\"\tFull-scale modal wind turbine tests: comparing shaker excitation with wind excitation\"\t2011.0\"\tbook-chapter\"\tSpringer New York\"\tStructural Dynamics and Renewable Energy, Volume 1\"\tN/A\"\t7988\n\"10.1056/NEJMoa1402121\"\tComprehensive, Integrative Genomic Analysis of Diffuse Lower-Grade Gliomas\"\t2015.0\"\tjournal-article\"\tNew England Journal of Medicine (NEJM/MMS)\"\tNew England Journal of Medicine\"\tGeneral Medicine\"\t6117\n\"10.1116/1.4904970\"\tPhotosensitive field emission study of SnS2 nanosheets\"\t2015.0\"\tjournal-article\"\tAmerican Vacuum Society\"\tJournal of Vacuum Science & Technology B, Nanotechnology and Microelectronics: Materials, Processing, Measurement, and Phenomena\"\tInstrumentation\"\t2991\n\"10.1103/PhysRevB.63.224204\"\tGriffiths effects and quantum critical points in dirty superconductors without spin-rotation invariance: One-dimensional examples\"\tN/A\"\tjournal-article\"\tAmerican Physical Society (APS)\"\tPhysical Review B\"\tCondensed Matter Physics\"\t2890\n\"10.1182/asheducation-2015.1.8\"\tIron deficiency: new insights into diagnosis and treatment\"\t2015.0\"\tjournal-article\"\tAmerican Society of Hematology\"\tHematology\"\tHematology\"\t2528\n\"10.4028/www.scientific.net/AMM.7-8.159\"\tMonitoring the Evolution of Fatigue in Corrugated Paperboard under Random Loads\"\tN/A\"\tjournal-article\"\tTrans Tech Publications\"\tApplied Mechanics and Materials\"\tN/A\"\t2266\n\"10.1111/j.1365-277X.2004.00520.x\"\tIntentional mis-reporting of food consumption and its relationship with body mass index and psychological scores in women\"\t2004.0\"\tjournal-article\"\tWiley-Blackwell\"\tJournal of Human Nutrition and Dietetics\"\tNutrition and Dietetics\"\t2241\n\"10.1002/pmic.200600525\"\tConifer defense against insects: Proteome analysis of Sitka spruce (Picea sitchensis) bark induced by mechanical wounding or feeding by white pine weevils (Pissodes strobi)\"\t2007.0\"\tjournal-article\"\tWiley-Blackwell\"\tPROTEOMICS\"\tBiochemistry\"\t2168\n\"10.1161/CIRCRESAHA.117.306290\"\tEfficient Gene Disruption in Cultured Primary Human Endothelial Cells by CRISPR/Cas9Novelty and Significance\"\t2015.0\"\tjournal-article\"\tOvid Technologies (Wolters Kluwer Health)\"\tCirculation Research\"\tPhysiology\"\t2001\n\"10.1002/smll.201002009\"\tGraphene-Based Materials: Synthesis, Characterization, Properties, and Applications\"\t2011.0\"\tjournal-article\"\tWiley-Blackwell\"\tSmall\"\tBiotechnology\"\t1806\n"}]},"apps":[],"jobName":"paragraph_1507262606333_1789104580","id":"20160814-113827_642005527","dateCreated":"2017-10-06T01:03:26-0300","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2472","user":"anonymous","dateFinished":"2017-10-06T01:14:46-0300","dateStarted":"2017-10-06T01:13:16-0300"},{"text":"","dateUpdated":"2017-10-06T01:03:26-0300","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507262606334_1790258827","id":"20160814-121759_363662491","dateCreated":"2017-10-06T01:03:26-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2473"}],"name":"proy1final","id":"2CWH9UT49","angularObjects":{"2CRBJ1TRK:shared_process":[],"2CQ6E5PGQ:shared_process":[],"2CRKEY1QU:shared_process":[],"2CRUJFVZ8:shared_process":[],"2CS97UD25:shared_process":[],"2CQXJMN8C:shared_process":[],"2CPYT3M2U:shared_process":[],"2CSHR5Z2N:shared_process":[],"2CSAYAARD:shared_process":[],"2CQYNJRPB:shared_process":[],"2CSRCJNV5:shared_process":[],"2CQNUZHKK:shared_process":[],"2CQYHV85D:shared_process":[],"2CQ67YZNF:shared_process":[],"2CQ84C23F:shared_process":[],"2CSMN7B9W:shared_process":[],"2CPTEBNRV:shared_process":[],"2CS6Z5AX2:shared_process":[],"2CRCN644M:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}